#!/usr/bin/env python3
"""
I5R5_OHLCVæ¨¡å‹å¿«é€Ÿæµ‹è¯•è„šæœ¬
å¿«é€ŸéªŒè¯æ‰€æœ‰æ¨¡å‹çš„åŠ è½½å’ŒåŸºæœ¬é¢„æµ‹åŠŸèƒ½
"""

import os
import sys
import yaml
import pandas as pd
import numpy as np
import torch
from __init__ import *
import utils as _U
import model as _M
import dataset as _D

def quick_test_all_models():
    """å¿«é€Ÿæµ‹è¯•æ‰€æœ‰æ¨¡å‹"""
    print("I5R5_OHLCVæ¨¡å‹å¿«é€Ÿæµ‹è¯•")
    print("=" * 40)
    
    config_dir = "configs/I5R5"
    model_dir = "models/I5R5_OHLCV"
    
    # è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶
    config_files = [f for f in os.listdir(config_dir) if f.endswith('.yml')]
    config_files.sort()
    
    results = []
    
    for config_file in config_files:
        print(f"\næµ‹è¯•: {config_file}")
        
        try:
            # åŠ è½½é…ç½®
            config_path = os.path.join(config_dir, config_file)
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            setting = _U.Dict2ObjParser(config).parse()
            
            # ç”Ÿæˆæ¨¡å‹æ–‡ä»¶å
            model_file = config_file.replace('.yml', '.tar').replace('I5R5_', 'I5R5_OHLCV_')
            model_path = os.path.join(model_dir, model_file)
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            if not os.path.exists(model_path):
                print(f"  âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")
                continue
            
            # åŠ è½½æ¨¡å‹
            model = _M.CNN5d()
            checkpoint = torch.load(model_path, map_location='cpu')
            model.load_state_dict(checkpoint['model_state_dict'])
            model.eval()
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            test_dataset = _D.ImageDataSet(
                win_size=setting.DATASET.LOOKBACK_WIN,
                start_date=setting.TEST.START_DATE,
                end_date=setting.TEST.END_DATE,
                mode='test',
                label=setting.TRAIN.LABEL,
                indicators=setting.DATASET.INDICATORS,
                show_volume=setting.DATASET.SHOW_VOLUME,
                parallel_num=setting.DATASET.PARALLEL_NUM
            )
            
            # ç”Ÿæˆå°‘é‡æµ‹è¯•æ•°æ®
            test_images = test_dataset.generate_images(0.1)  # åªä½¿ç”¨10%çš„æ•°æ®è¿›è¡Œå¿«é€Ÿæµ‹è¯•
            
            if len(test_images) == 0:
                print(f"  âŒ æ²¡æœ‰ç”Ÿæˆæµ‹è¯•æ•°æ®")
                continue
            
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            # æ¨¡å‹æœŸæœ›è¾“å…¥æ ¼å¼: [batch_size, height, width]ï¼Œæ¨¡å‹å†…éƒ¨ä¼šæ·»åŠ é€šé“ç»´åº¦
            image_tensors = []
            for img in test_images[:10]:  # åªæµ‹è¯•å‰10ä¸ªæ ·æœ¬
                img_tensor = torch.FloatTensor(img[0])  # img[0] æ˜¯numpyæ•°ç»„ï¼Œå½¢çŠ¶ä¸º [height, width]
                image_tensors.append(img_tensor)
            
            images = torch.stack(image_tensors)  # [batch_size, height, width]
            labels = torch.LongTensor([img[1] for img in test_images[:10]]) if setting.TRAIN.LABEL == 'RET5' else torch.LongTensor([img[2] for img in test_images[:10]])
            
            print(f"  ğŸ” å¼ é‡å½¢çŠ¶: {images.shape}")
            
            # è¿›è¡Œé¢„æµ‹
            with torch.no_grad():
                
                outputs = model(images)
                predictions = torch.argmax(outputs, dim=1)
                probabilities = torch.softmax(outputs, dim=1)
            
            # è®¡ç®—åŸºæœ¬å‡†ç¡®ç‡
            accuracy = (predictions == labels).float().mean().item()
            
            print(f"  âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"  ğŸ“Š æµ‹è¯•æ ·æœ¬æ•°: {len(test_images)}")
            print(f"  ğŸ¯ å¿«é€Ÿå‡†ç¡®ç‡: {accuracy:.4f}")
            print(f"  ğŸ“… è®­ç»ƒå‘¨æœŸ: {setting.DATASET.START_DATE}-{setting.DATASET.END_DATE}")
            print(f"  ğŸ§ª æµ‹è¯•å‘¨æœŸ: {setting.TEST.START_DATE}-{setting.TEST.END_DATE}")
            print(f"  ğŸ·ï¸  æ ‡ç­¾ç±»å‹: {setting.TRAIN.LABEL}")
            print(f"  ğŸ“ˆ åŒ…å«æˆäº¤é‡: {setting.DATASET.SHOW_VOLUME}")
            
            results.append({
                'config': config_file,
                'model': model_file,
                'accuracy': accuracy,
                'test_samples': len(test_images),
                'train_period': f"{setting.DATASET.START_DATE}-{setting.DATASET.END_DATE}",
                'test_period': f"{setting.TEST.START_DATE}-{setting.TEST.END_DATE}",
                'label': setting.TRAIN.LABEL,
                'show_volume': setting.DATASET.SHOW_VOLUME
            })
            
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
            continue
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    if results:
        print(f"\n{'='*50}")
        print("å¿«é€Ÿæµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
        print(f"{'='*50}")
        
        df = pd.DataFrame(results)
        
        print(f"æˆåŠŸæµ‹è¯•æ¨¡å‹æ•°: {len(results)}")
        print(f"å¹³å‡å‡†ç¡®ç‡: {df['accuracy'].mean():.4f}")
        print(f"æœ€é«˜å‡†ç¡®ç‡: {df['accuracy'].max():.4f}")
        print(f"æœ€ä½å‡†ç¡®ç‡: {df['accuracy'].min():.4f}")
        
        print(f"\næœ€ä½³æ¨¡å‹:")
        best_model = df.loc[df['accuracy'].idxmax()]
        print(f"  é…ç½®æ–‡ä»¶: {best_model['config']}")
        print(f"  æ¨¡å‹æ–‡ä»¶: {best_model['model']}")
        print(f"  å‡†ç¡®ç‡: {best_model['accuracy']:.4f}")
        print(f"  è®­ç»ƒå‘¨æœŸ: {best_model['train_period']}")
        print(f"  æµ‹è¯•å‘¨æœŸ: {best_model['test_period']}")
        
        # ä¿å­˜ç»“æœ
        df.to_csv('quick_test_results.csv', index=False)
        print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: quick_test_results.csv")
        
        # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹ç»“æœ
        print(f"\næ‰€æœ‰æ¨¡å‹ç»“æœ:")
        print(df[['config', 'accuracy', 'test_samples', 'train_period']].to_string(index=False))
        
    else:
        print("æ²¡æœ‰æˆåŠŸæµ‹è¯•ä»»ä½•æ¨¡å‹")

if __name__ == "__main__":
    quick_test_all_models()
