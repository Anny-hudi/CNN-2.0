{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from train_in_roll import *\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataSet(win_size=5, start_date=20091231, end_date=20111231, mode='train', indicators={'MA':[20]}, show_volume=True)\n",
    "image_set = dataset.generate_images(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(image_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAN_VAL_SPLIT_RATIO = 0.7\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-5\n",
    "LABEL_TYPE = 'RET1'\n",
    "\n",
    "train_loader_size = int(len(image_set)*TRIAN_VAL_SPLIT_RATIO)\n",
    "torch_loader_size = len(image_set) - train_loader_size\n",
    "\n",
    "train_loader, val_loader = torch.utils.data.random_split(image_set, [train_loader_size, torch_loader_size])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_loader, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_loader, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input, ret1, ret5, ret20) in enumerate(val_loader):\n",
    "    assert LABEL_TYPE in ['RET1', 'RET5', 'RET20'], f\"Wrong Label Type: {LABEL_TYPE}\"\n",
    "    if LABEL_TYPE == 'RET1':\n",
    "        labels = ret1\n",
    "    elif LABEL_TYPE == 'RET5':\n",
    "        labels = ret5\n",
    "    else:\n",
    "        labels = ret20\n",
    "\n",
    "    labels = (1-labels).unsqueeze(1) @ torch.LongTensor([1., 0.]).unsqueeze(1).T + labels.unsqueeze(1) @ torch.LongTensor([0, 1]).unsqueeze(1).T\n",
    "    labels = labels.to(torch.float32)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 32, 15])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(1, 64, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))), # output size: [N, 64, 32, 15]\n",
    "            ('BN', nn.BatchNorm2d(64, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 64, 16, 15]\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN5d(nn.Module):\n",
    "    # Input: [N, (1), 32, 15]; Output: [N, 2]\n",
    "    # Two Convolution Blocks\n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN5d, self).__init__()\n",
    "        self.conv1 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(1, 64, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))), # output size: [N, 64, 32, 15]\n",
    "            ('BN', nn.BatchNorm2d(64, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 64, 16, 15]\n",
    "        ]))\n",
    "        self.conv1 = self.conv1.apply(self.init_weights)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(64, 128, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))), # output size: [N, 128, 16, 15]\n",
    "            ('BN', nn.BatchNorm2d(128, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 128, 8, 15]\n",
    "        ]))\n",
    "        self.conv2 = self.conv2.apply(self.init_weights)\n",
    "\n",
    "        self.DropOut = nn.Dropout(p=0.5)\n",
    "        self.FC = nn.Linear(15360, 2)\n",
    "        self.init_weights(self.FC)\n",
    "        self.Softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x): # input: [N, 32, 15]\n",
    "        x = x.unsqueeze(1).to(torch.float32)   # output size: [N, 1, 32, 15]\n",
    "        x = self.conv1(x) # output size: [N, 64, 16, 15]\n",
    "        x = self.conv2(x) # output size: [N, 128, 8, 15]\n",
    "        x = self.DropOut(x.view(x.shape[0], -1))\n",
    "        x = self.FC(x) # output size: [N, 2]\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN5d(\n",
       "  (conv1): Sequential(\n",
       "    (Conv): Conv2d(1, 64, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1))\n",
       "    (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU): ReLU()\n",
       "    (Max-Pool): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (Conv): Conv2d(64, 128, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1))\n",
       "    (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU): ReLU()\n",
       "    (Max-Pool): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (DropOut): Dropout(p=0.5, inplace=False)\n",
       "  (FC): Linear(in_features=15360, out_features=2, bias=True)\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = CNN5d()\n",
    "model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = nn.Conv2d(1, 64, (5, 3), padding=(3, 1), stride=(3, 1), dilation=(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(cc, nn.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN20d(nn.Module):\n",
    "    # Input: [N, (1), 64, 60]; Output: [N, 2]\n",
    "    # Three Convolution Blocks\n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN20d, self).__init__()\n",
    "        self.conv1 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(1, 64, (5, 3), padding=(3, 1), stride=(3, 1), dilation=(2, 1))), # output size: [N, 64, 21, 60]\n",
    "            ('BN', nn.BatchNorm2d(64, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 64, 10, 60]\n",
    "        ]))\n",
    "        self.conv1 = self.conv1.apply(self.init_weights)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(64, 128, (5, 3), padding=(3, 1), stride=(1, 1), dilation=(1, 1))), # output size: [N, 128, 12, 60]\n",
    "            ('BN', nn.BatchNorm2d(128, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 128, 6, 60]\n",
    "        ]))\n",
    "        self.conv2 = self.conv2.apply(self.init_weights)\n",
    "        \n",
    "        self.conv3 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(128, 256, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))), # output size: [N, 256, 6, 60]\n",
    "            ('BN', nn.BatchNorm2d(256, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 256, 3, 60]\n",
    "        ]))\n",
    "        self.conv3 = self.conv3.apply(self.init_weights)\n",
    "\n",
    "        self.DropOut = nn.Dropout(p=0.5)\n",
    "        self.FC = nn.Linear(46080, 2)\n",
    "        self.init_weights(self.FC)\n",
    "        self.Softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x): # input: [N, 64, 60]\n",
    "        x = x.unsqueeze(1).to(torch.float32)   # output size: [N, 1, 64, 60]\n",
    "        x = self.conv1(x) # output size: [N, 64, 10, 60]\n",
    "        x = self.conv2(x) # output size: [N, 128, 6, 60]\n",
    "        x = self.conv3(x) # output size: [N, 256, 3, 60]\n",
    "        x = self.DropOut(x.view(x.shape[0], -1))\n",
    "        x = self.FC(x) # output size: [N, 2]\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Dropout(p=0.2)\n",
    "input = torch.randn(20, 16)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN20d(\n",
       "  (conv1): Sequential(\n",
       "    (Conv): Conv2d(1, 64, kernel_size=(5, 3), stride=(3, 1), padding=(3, 1), dilation=(2, 1))\n",
       "    (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU): ReLU()\n",
       "    (Max-Pool): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (Conv): Conv2d(64, 128, kernel_size=(5, 3), stride=(1, 1), padding=(3, 1))\n",
       "    (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU): ReLU()\n",
       "    (Max-Pool): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (Conv): Conv2d(128, 256, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1))\n",
       "    (BN): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ReLU): ReLU()\n",
       "    (Max-Pool): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (DropOut): Dropout(p=0.5, inplace=False)\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model20 = CNN20d()\n",
    "model20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll = [((20091231, 20111231), (20111231, 20121231))]\n",
    "models = [CNN20d().to('cuda'),CNN20d().to('cuda'),CNN20d().to('cuda')]\n",
    "train_model(models, train_loader, val_loader, num_epochs=10, learning_rate=0.001, batch_size=32, device='cuda' , weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    print('train one epoch')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model5(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8413, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(output, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
