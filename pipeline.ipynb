{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from model import *\n",
    "from train_in_roll import *\n",
    "from dataloader import *\n",
    "import dataloader as _D\n",
    "reload(_D)\n",
    "import utils as _U\n",
    "reload(_U)\n",
    "from collections import OrderedDict\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_config.yml', 'r') as f:\n",
    "    args = _U.Dict2ObjParser(yaml.safe_load(f)).parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "if args.dataset.show_volume:\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO TRAINING DATASET \n",
    "LOOKBACK_WIN_SIZE = 5\n",
    "START_DATE = 20091231\n",
    "END_DATE = 20111231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load Data] | 2023-04-18 09:29:17 Done | Using  7.736 seconds\n",
      "TRAIN DataSet Initialized\n",
      " \t - Image Size:   (32, 15)\n",
      " \t - Time Period:  20091231 - 20111231\n",
      " \t - Indicators:   {'MA': [20]}\n",
      " \t - Volume Shown: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Images: 100%|██████████| 2283/2283 [02:09<00:00, 17.64it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = _D.ImageDataSet(win_size = args.dataset.lookback_win_size, \\\n",
    "                            start_date = args.dataset.start_date, \\\n",
    "                            end_date = args.dataset.end_date, \\\n",
    "                            mode = args.dataset.mode, \\\n",
    "                            indicators = args.dataset.indicators, \\\n",
    "                            show_volume=True)\n",
    "\n",
    "image_set = dataset.generate_images(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(image_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAN_VAL_SPLIT_RATIO = 0.7\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-5\n",
    "LABEL_TYPE = 'RET1'\n",
    "\n",
    "train_loader_size = int(len(image_set)*TRIAN_VAL_SPLIT_RATIO)\n",
    "torch_loader_size = len(image_set) - train_loader_size\n",
    "\n",
    "train_loader, val_loader = torch.utils.data.random_split(image_set, [train_loader_size, torch_loader_size])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_loader, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_loader, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input, ret1, ret5, ret20) in enumerate(val_loader):\n",
    "    assert LABEL_TYPE in ['RET1', 'RET5', 'RET20'], f\"Wrong Label Type: {LABEL_TYPE}\"\n",
    "    if LABEL_TYPE == 'RET1':\n",
    "        labels = ret1\n",
    "    elif LABEL_TYPE == 'RET5':\n",
    "        labels = ret5\n",
    "    else:\n",
    "        labels = ret20\n",
    "\n",
    "    labels = (1-labels).unsqueeze(1) @ torch.LongTensor([1., 0.]).unsqueeze(1).T + labels.unsqueeze(1) @ torch.LongTensor([0, 1]).unsqueeze(1).T\n",
    "    labels = labels.to(torch.float32)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(1, 64, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))), # output size: [N, 64, 32, 15]\n",
    "            ('BN', nn.BatchNorm2d(64, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 64, 16, 15]\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN5d(nn.Module):\n",
    "    # Input: [N, (1), 32, 15]; Output: [N, 2]\n",
    "    # Two Convolution Blocks\n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN5d, self).__init__()\n",
    "        self.conv1 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(1, 64, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))), # output size: [N, 64, 32, 15]\n",
    "            ('BN', nn.BatchNorm2d(64, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 64, 16, 15]\n",
    "        ]))\n",
    "        self.conv1 = self.conv1.apply(self.init_weights)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(64, 128, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))), # output size: [N, 128, 16, 15]\n",
    "            ('BN', nn.BatchNorm2d(128, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 128, 8, 15]\n",
    "        ]))\n",
    "        self.conv2 = self.conv2.apply(self.init_weights)\n",
    "\n",
    "        self.DropOut = nn.Dropout(p=0.5)\n",
    "        self.FC = nn.Linear(15360, 2)\n",
    "        self.init_weights(self.FC)\n",
    "        self.Softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x): # input: [N, 32, 15]\n",
    "        x = x.unsqueeze(1).to(torch.float32)   # output size: [N, 1, 32, 15]\n",
    "        x = self.conv1(x) # output size: [N, 64, 16, 15]\n",
    "        x = self.conv2(x) # output size: [N, 128, 8, 15]\n",
    "        x = self.DropOut(x.view(x.shape[0], -1))\n",
    "        x = self.FC(x) # output size: [N, 2]\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = CNN5d()\n",
    "model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = nn.Conv2d(1, 64, (5, 3), padding=(3, 1), stride=(3, 1), dilation=(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(cc, nn.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN20d(nn.Module):\n",
    "    # Input: [N, (1), 64, 60]; Output: [N, 2]\n",
    "    # Three Convolution Blocks\n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN20d, self).__init__()\n",
    "        self.conv1 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(1, 64, (5, 3), padding=(3, 1), stride=(3, 1), dilation=(2, 1))), # output size: [N, 64, 21, 60]\n",
    "            ('BN', nn.BatchNorm2d(64, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 64, 10, 60]\n",
    "        ]))\n",
    "        self.conv1 = self.conv1.apply(self.init_weights)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(64, 128, (5, 3), padding=(3, 1), stride=(1, 1), dilation=(1, 1))), # output size: [N, 128, 12, 60]\n",
    "            ('BN', nn.BatchNorm2d(128, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 128, 6, 60]\n",
    "        ]))\n",
    "        self.conv2 = self.conv2.apply(self.init_weights)\n",
    "        \n",
    "        self.conv3 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(128, 256, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))), # output size: [N, 256, 6, 60]\n",
    "            ('BN', nn.BatchNorm2d(256, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2,1))) # output size: [N, 256, 3, 60]\n",
    "        ]))\n",
    "        self.conv3 = self.conv3.apply(self.init_weights)\n",
    "\n",
    "        self.DropOut = nn.Dropout(p=0.5)\n",
    "        self.FC = nn.Linear(46080, 2)\n",
    "        self.init_weights(self.FC)\n",
    "        self.Softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x): # input: [N, 64, 60]\n",
    "        x = x.unsqueeze(1).to(torch.float32)   # output size: [N, 1, 64, 60]\n",
    "        x = self.conv1(x) # output size: [N, 64, 10, 60]\n",
    "        x = self.conv2(x) # output size: [N, 128, 6, 60]\n",
    "        x = self.conv3(x) # output size: [N, 256, 3, 60]\n",
    "        x = self.DropOut(x.view(x.shape[0], -1))\n",
    "        x = self.FC(x) # output size: [N, 2]\n",
    "        x = self.Softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Dropout(p=0.2)\n",
    "input = torch.randn(20, 16)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model20 = CNN20d()\n",
    "model20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll = [((20091231, 20111231), (20111231, 20121231))]\n",
    "models = [CNN20d().to('cuda'),CNN20d().to('cuda'),CNN20d().to('cuda')]\n",
    "train_model(models, train_loader, val_loader, num_epochs=10, learning_rate=0.001, batch_size=32, device='cuda' , weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    print('train one epoch')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model5(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(output, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
